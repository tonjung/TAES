{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network\n",
    "**Using Neural Networks to predict essay grades using vectorized essays** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks were used to predict the grade of the essay by 90% of the data\n",
    "training and 10% of the data testing. Three layers of the neural network were created\n",
    "with an input layer, two layers on neurons and with an output node. \n",
    "\n",
    "Let's look at the architecture, initialization and cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from essay2vec import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight and Bias Variable**\n",
    "\n",
    "This neural network employed a linear summation of biases (b) and a product of weights (W) and\n",
    "data of that layer (x) according to an equation below:\n",
    "\n",
    "Y = W*x + b\n",
    "\n",
    "The weights were initiated as the shape of [previous layer, next layer], assigned to a\n",
    "value of 0.1. These weights were revised while the neural network was trained. The\n",
    "weights were optimized with the increasing epochs number. As a result, the accuracy of\n",
    "the training and response variables testing could be monitored. The biases were\n",
    "initiated as the shape of [next layer]. Similarly, the biases were optimized with the\n",
    "increasing epochs number during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.zeros(shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network Architecture**\n",
    "\n",
    "A feed-forward neural network architecture was employed. The number of input\n",
    "nodes was the number of training essay features (300). These were fed into a 500 nodes\n",
    "layer, the input of these nodes was activated by a ReLU function, that was obtained\n",
    "from the matrix operation of weights, input nodes, and biases. Then the first layer\n",
    "output was fed into 750 nodes layer, the input was activated by a ReLU function\n",
    "similarly. Finally, the output node created a regression result.\n",
    "The employed loss function in optimization was the Mean Square Error of the\n",
    "predicted score versus the real score. Adam-Optimizer was used to find the best-\n",
    "optimized loss function that trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "hidden_nodes_1 = 500\n",
    "hidden_nodes_2 = 750\n",
    "size = testDataVecs.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, size))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    \n",
    "    tf_test_dataset = tf.constant(testDataVecs)\n",
    "      \n",
    "    layer1_weights = weight_variable([size, hidden_nodes_1])\n",
    "    layer1_biases = bias_variable([hidden_nodes_1]) \n",
    "    \n",
    "    layer2_weights = weight_variable([hidden_nodes_1, hidden_nodes_2])\n",
    "    layer2_biases = bias_variable([hidden_nodes_2])\n",
    "    \n",
    "    layer3_weights = weight_variable([hidden_nodes_2, 1])\n",
    "    layer3_biases = bias_variable([1])\n",
    "    \n",
    "    def model(data):\n",
    "        with tf.name_scope(\"Layer_1\"):\n",
    "            layer1 = tf.nn.relu(tf.matmul(data, layer1_weights) + layer1_biases)\n",
    "        \n",
    "        with tf.name_scope(\"Layer_2\"):\n",
    "            \n",
    "            layer2 = tf.nn.relu(tf.matmul(layer1, layer2_weights) + layer2_biases)\n",
    "\n",
    "        with tf.name_scope(\"Layer_3\"):\n",
    "            layer3 = tf.nn.relu(tf.matmul(layer2, layer3_weights) + layer3_biases)\n",
    "        return layer3\n",
    "    \n",
    "    # Training computation.\n",
    "    yhat = model(tf_train_dataset)\n",
    "    \n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        loss = tf.reduce_mean(tf.square(yhat - tf_train_labels))\n",
    "    \n",
    "    # Optimizer.\n",
    "    # learning rate decay\n",
    "    global_step = tf.Variable(0)  # count  number of steps taken.\n",
    "    start_learning_rate = 0.001\n",
    "    learning_rate = tf.train.exponential_decay(start_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "    \n",
    "    with tf.name_scope(\"Train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = yhat\n",
    "    test_prediction = model(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Testing Prediction**\n",
    "\n",
    "The neural network was then trained on essay batches. The error minimization\n",
    "was used to optimize the learning rate by adjusting the weights and biases of each layer.\n",
    "The accuracy of each epoch was calculated with the spearman correlation at each epoch\n",
    "and lastly, the spearman score for the test set was calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch Loss at Epoch 0: 4.203\n",
      "Minibatch Spearman Score: 0.1206\n",
      "Minibatch Loss at Epoch 500: 0.415\n",
      "Minibatch Spearman Score: 0.3273\n",
      "Minibatch Loss at Epoch 1000: 0.355\n",
      "Minibatch Spearman Score: 0.4419\n",
      "Minibatch Loss at Epoch 1500: 0.304\n",
      "Minibatch Spearman Score: 0.4947\n",
      "Minibatch Loss at Epoch 2000: 0.283\n",
      "Minibatch Spearman Score: 0.5844\n",
      "Minibatch Loss at Epoch 2500: 0.293\n",
      "Minibatch Spearman Score: 0.5514\n",
      "Minibatch Loss at Epoch 3000: 0.305\n",
      "Minibatch Spearman Score: 0.5550\n",
      "Test Spearman Score: 0.4837\n"
     ]
    }
   ],
   "source": [
    "test_preds = pd.DataFrame()\n",
    "# Re-define the function to include the keep probability\n",
    "l_array = []\n",
    "start = timeit.timeit()\n",
    "num_epochs = 3001\n",
    "def run_session(num_epochs, name):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        writer = tf.summary.FileWriter(\"logs/\", session.graph)\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        for epoch in range(num_epochs):\n",
    "            offset = (epoch * batch_size) % (y_train.shape[0] - batch_size)\n",
    "            batch_data = trainDataVecs[offset:(offset + batch_size), :]\n",
    "            batch_labels = y_train[offset:(offset + batch_size)]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            l_array.append(l)\n",
    "            if (epoch % 500 == 0):\n",
    "                print(\"Minibatch Loss at Epoch {}: {:.3f}\".format(epoch, l))\n",
    "                rho, pval = (spearmanr(predictions, batch_labels))\n",
    "                print(\"Minibatch Spearman Score: {:.4f}\".format(rho))\n",
    "        final_rho, pval = spearmanr(test_prediction.eval(), y_test)\n",
    "        print(\"Test Spearman Score: {:.4f}\".format(final_rho))\n",
    "        test_preds[name] = test_prediction.eval().ravel()\n",
    "        filesave = np.zeros((len(y_test), 2))\n",
    "        to_use = test_prediction.eval()\n",
    "        \n",
    "        for ii in range(len(y_test)):           \n",
    "            filesave[ii, 0] = y_test[ii]\n",
    "            filesave[ii, 1] = to_use[ii]\n",
    "        \n",
    "        np.savetxt('savetest.txt', filesave, delimiter=\",\", fmt=\"%d\") \n",
    "        \n",
    "run_session(num_epochs, \"Deep_NN\")\n",
    "total = timeit.timeit() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss vs Epoch**\n",
    "\n",
    "As expected, the loss was minimized while the number of epochs was increased\n",
    "in Figure 1. This implied that the MSE loss function was lowered during the training\n",
    "and the optimal answer was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_epochs), l_array, '.')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.title(\"Cost vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Having tested the Neural Network on 10% of the data and trained on 90% of the data, the Spearman score was 0.4837, with quite low computation time. This means the accuracy of the model is moderate.  More essays were needed, or the topic of the essay should be very specific for more accuracy.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
